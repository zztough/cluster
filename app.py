import streamlit as st
import spacy
from spacy_streamlit import visualize_ner
import jieba
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN, Birch
from sklearn.decomposition import PCA
from sklearn.manifold import TSNE
from sklearn.metrics import silhouette_score, davies_bouldin_score
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import matplotlib # For font management
import matplotlib.font_manager # For font management
import os # For checking font file existence
from scipy.cluster.hierarchy import dendrogram, linkage

# A simple text classifier
from sklearn.naive_bayes import MultinomialNB
from sklearn.linear_model import LogisticRegression
from sklearn.svm import LinearSVC
from sklearn.pipeline import Pipeline

# New imports for advanced visualizations
from wordcloud import WordCloud
import plotly.express as px
import plotly.graph_objects as go

# --- Page Configuration ---
st.set_page_config(page_title="‰∏≠ÊñáNLPÊô∫ËÉΩÂàÜÊûêÂπ≥Âè∞", page_icon="ü§ñ", layout="wide")

# --- Custom CSS for Dark Theme (OpenAI-like) ---
custom_css = """
<style>
    /* Base styles */
    body {
        font-family: 'Noto Sans CJK SC', 'Helvetica Neue', Arial, sans-serif; /* Ensure CJK font is prioritized */
        color: #D1D5DB; /* Light gray text */
        background-color: #0F172A; /* Dark blue-gray background */
    }
    .stApp {
        background-color: #0F172A; /* Dark blue-gray background */
    }

    /* Titles and Headers - Unified Sizes */
    h1, h2, h3, h4, h5 {
        color: #F3F4F6; /* Lighter text for headers */
    }
    h1 { /* For the main page title in render_homepage */
        text-align: center;
        padding-bottom: 20px;
        font-size: 2.6em; /* Unified */
        font-weight: 600;
        border-bottom: 2px solid #374151;
    }
    h2 { /* Main section headers (st.header for "1. ËæìÂÖ•ÊñáÊú¨", "2. Êü•ÁúãÂàÜÊûêÁªìÊûú") */
        margin-top: 2rem;
        margin-bottom: 1rem;
        padding-bottom: 0.5rem;
        font-size: 2.0em; /* Unified & Increased */
        font-weight: 500;
        border-bottom: 1px solid #374151;
    }
    h3 { /* Sub-section headers (st.subheader for "‚úÇÔ∏è ‰∏≠ÊñáÂàÜËØçÁªìÊûú", "üî¶ È´ò‰∫ÆÂÆû‰Ωì:") */
        font-size: 1.7em; /* Unified & Increased */
        font-weight: 500;
        color: #E5E7EB;
        margin-top: 1.5rem;
        margin-bottom: 0.8rem;
    }
    h4 { /* Sub-sub-sections (e.g., "üìã ËØÜÂà´Âà∞ÁöÑÂÆû‰ΩìÂàóË°®", "üìè ËÅöÁ±ªËØÑ‰º∞ÊåáÊ†á") */
        font-size: 1.4em; /* Unified & Increased */
        font-weight: 500;
        color: #E0E0E0;
        margin-top: 1.5rem;
        margin-bottom: 0.7rem;
        padding-bottom: 0.4rem;
        border-bottom: 1px dashed #4B5563;
    }
    h5 { /* Smaller titles (e.g., word frequency, KMeans/DBSCAN ÂèÇÊï∞) */
        font-size: 1.2em; /* Unified & Increased */
        font-weight: 500;
        color: #E5E7EB;
        margin-top: 1rem;
        margin-bottom: 0.5rem;
    }

    /* Sidebar styling */
    div[data-testid="stSidebar"] > div:first-child {
        background-color: #1E293B;
        border-right: 1px solid #374151;
    }
    div[data-testid="stSidebar"] .stRadio > label { /* Sidebar Navigation Radio Label */
        font-size: 1.2em !important; /* Increased */
        font-weight: 500;
        color: #E5E7EB;
        padding-bottom: 5px; /* Add some space below the main label */
    }
     div[data-testid="stSidebar"] .stRadio div[role="radiogroup"] > label { /* Sidebar Radio button options */
        padding: 7px 0px !important; /* Increased padding */
        font-size: 1.1em !important; /* Increased */
    }
    div[data-testid="stSidebar"] p { /* Sidebar text like ¬© 2024 */
        color: #9CA3AF;
    }
     div[data-testid="stSidebar"] h1, /* Sidebar Header */
     div[data-testid="stSidebar"] h2,
     div[data-testid="stSidebar"] h3,
     div[data-testid="stSidebar"] h4 {
        color: #F3F4F6;
     }

    /* Input widgets styling - Increase label font size for main content area */
    .main div[data-testid="stTextInput"] label,
    .main div[data-testid="stTextArea"] label,
    .main div[data-testid="stSelectbox"] label,
    .main div[data-testid="stNumberInput"] label,
    .main div[data-testid="stRadio"] > label, /* For main content radio buttons */
    .main div[data-testid="stFileUploader"] label,
    .main div[data-testid="stDateInput"] label,
    .main div[data-testid="stTimeInput"] label,
    .main div[data-testid="stColorPicker"] label,
    .main div[data-testid="stSlider"] label {
        font-size: 1.15em !important; /* Increased font size for widget labels in main area */
        color: #E5E7EB !important;
        margin-bottom: 0.4rem !important; 
    }

    div[data-testid="stTextInput"] input,
    div[data-testid="stTextArea"] textarea,
    div[data-testid="stSelectbox"] div[data-baseweb="select"] > div, /* Selectbox */
    div[data-testid="stNumberInput"] input {
        background-color: #374151 !important; /* Darker input background */
        color: #F3F4F6 !important; /* Light text in inputs */
        border: 1px solid #4B5563 !important;
        border-radius: 0.375rem !important; /* Tailwind-like rounded-md */
    }
    div[data-testid="stTextArea"] textarea {
        min-height: 150px; /* Ensure text area is reasonably sized */
    }

    /* Button styling */
    div[data-testid="stButton"] > button {
        background-color: #2563EB; /* OpenAI-like blue */
        color: white;
        border: none;
        padding: 0.6rem 1.2rem;
        border-radius: 0.375rem;
        font-weight: 500;
        transition: background-color 0.2s ease;
    }
    div[data-testid="stButton"] > button:hover {
        background-color: #1D4ED8; /* Darker blue on hover */
    }
    div[data-testid="stButton"] > button:focus {
        outline: none !important;
        box-shadow: 0 0 0 3px rgba(59, 130, 246, 0.5) !important; /* Blue focus ring */
    }
    
    /* Radio buttons in main content */
    div[data-testid="stRadio"] label {
        font-size: 1em;
    }

    /* Slider styling */
    div[data-testid="stSlider"] {
        /* color: #60A5FA; */ /* Blue for slider track/thumb - Use Streamlit's default theming for this if possible */
    }


    /* Expander styling */
    .st-expander {
        border: 1px solid #374151;
        border-radius: 0.5rem; /* Tailwind rounded-lg */
        /* background-color: #1E293B; */ /* Background for expander content area - Let Streamlit handle content bg */
    }
    .st-expander header {
        background-color: #374151; /* Header of expander */
        color: #F3F4F6;
        padding: 0.75rem 1rem;
        border-top-left-radius: 0.5rem;
        border-top-right-radius: 0.5rem;
        border-bottom: 1px solid #1E293B; /* Separator for header */
        font-size: 1.25em !important; /* Increased font size for expander headers */
        font-weight: 500 !important;
    }
    .st-expander header:hover {
        background-color: #4B5563;
    }
    .st-expander div[data-testid="stExpanderDetails"] {
         background-color: #1E293B; /* Content area of expander */
         padding: 1rem;
         border-bottom-left-radius: 0.5rem;
         border-bottom-right-radius: 0.5rem;
    }


    /* Dataframes, Tables, Info/Warning/Error boxes */
    div[data-testid="stDataFrame"],
    div[data-testid="stTable"] { /* st.table is not used, but good to have */
        border-radius: 0.375rem;
        overflow: hidden; /* Ensures border-radius clips content */
    }
    div[data-testid="stInfo"],
    div[data-testid="stWarning"],
    div[data-testid="stError"],
    div[data-testid="stSuccess"] {
        border-radius: 0.375rem;
        padding: 1rem;
        color: #F3F4F6; /* Ensure text is light */
    }
    div[data-testid="stInfo"] { background-color: rgba(59, 130, 246, 0.2); border-left: 5px solid #3B82F6; } /* Blueish Info */
    div[data-testid="stSuccess"] { background-color: rgba(16, 185, 129, 0.2); border-left: 5px solid #10B981; } /* Greenish Success */
    div[data-testid="stWarning"] { background-color: rgba(245, 158, 11, 0.2); border-left: 5px solid #F59E0B; } /* Amber/Orange Warning */
    div[data-testid="stError"] { background-color: rgba(239, 68, 68, 0.2); border-left: 5px solid #EF4444; } /* Reddish Error */


    /* Metric styling */
    div[data-testid="stMetric"] {
        background-color: #1E293B;
        border: 1px solid #374151;
        padding: 1rem 1.5rem;
        border-radius: 0.5rem;
    }
    div[data-testid="stMetric"] > label { /* Metric label */
        color: #9CA3AF; /* Muted label color */
        font-size: 0.9em;
    }
    div[data-testid="stMetric"] > div[data-testid="stMetricValue"] { /* Metric value */
        color: #F3F4F6;
        font-size: 2em; 
        font-weight: 600;
    }
    
    /* Plotly chart container - make sure it blends */
    div[data-testid="stPlotlyChart"] {
        border-radius: 0.375rem;
        overflow: hidden; /* Clip contents like corners */
    }

    /* Matplotlib chart container */
    div[data-testid="stImage"] > img { /* For st.pyplot */
         border-radius: 0.375rem;
         background-color: transparent; /* Ensure image background doesn't override */
    }
    
    /* Horizontal Divider */
    hr {
        border-top: 1px solid #374151;
    }

    /* Links */
    a {
        color: #60A5FA; /* Light blue for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
        color: #93C5FD; /* Lighter blue on hover */
    }
    
    /* Feature card styling for homepage */
    .feature-card {
        background-color: #1E293B; 
        padding: 1.5rem;
        border-radius: 0.5rem; 
        border: 1px solid #374151;
        margin-bottom: 1.2rem; /* Increased margin */
        transition: transform 0.2s ease-in-out, box-shadow 0.2s ease-in-out;
        height: calc(100% - 1.2rem); /* Fill height minus margin for better alignment */
        display: flex; /* For vertical alignment of content */
        flex-direction: column; /* Stack content vertically */
    }
    .feature-card:hover {
        transform: translateY(-5px);
        box-shadow: 0 8px 16px rgba(0,0,0,0.25); /* Enhanced shadow */
    }
    .feature-card h3 { 
        font-size: 1.4em; /* Slightly larger */
        color: #F3F4F6;
        margin-top: 0;
        margin-bottom: 0.75rem; /* Increased margin */
        border-bottom: none; 
        line-height: 1.3;
    }
    .feature-card p { 
        font-size: 0.95em;
        color: #D1D5DB;
        line-height: 1.6;
        flex-grow: 1; /* Allow p to take available space */
    }
    /* End of Feature card styling */

    /* Ensure Streamlit's default spinner is visible on dark background */
    .stSpinner > div {
        border-top-color: #2563EB !important; /* Primary button color for spinner */
        border-right-color: transparent !important;
        border-bottom-color: transparent !important;
        border-left-color: transparent !important;
    }

</style>
"""
st.markdown(custom_css, unsafe_allow_html=True)

# --- Model Loading ---
@st.cache_resource # Use st.cache_resource for models
def load_spacy_model(model_name="zh_core_web_sm"):
    """Âä†ËΩΩspaCyÊ®°ÂûãÔºåÂ¶ÇÊûúÊú™ÊâæÂà∞ÊàñÂèëÁîüÂÖ∂‰ªñÈîôËØØÂàôÊèêÁ§∫Âπ∂ÂÅúÊ≠¢„ÄÇ"""
    try:
        nlp = spacy.load(model_name)
        return nlp
    except OSError:
        st.error(f"SpaCyÊ®°Âûã '{model_name}' Êú™ÊâæÂà∞„ÄÇËØ∑Âú®ÁªàÁ´ØËøêË°å: python -m spacy download {model_name}")
        st.stop()
    except Exception as e:
        st.error(f"Âä†ËΩΩSpaCyÊ®°Âûã '{model_name}' Êó∂ÂèëÁîüÊÑèÂ§ñÈîôËØØ: {e}")
        st.error("ËøôÂèØËÉΩÊòØÁî±‰∫é‰æùËµñÂ∫ìÁâàÊú¨‰∏çÂÖºÂÆπÔºà‰æãÂ¶Ç NumPy ‰∏é spaCy/thinc ÁöÑÂÖºÂÆπÊÄßÈóÆÈ¢òÔºâÊàñÂÖ∂‰ªñÈÖçÁΩÆÈóÆÈ¢ò„ÄÇËØ∑Ê£ÄÊü•ÊéßÂà∂Âè∞ËæìÂá∫‰ª•Ëé∑ÂèñËØ¶ÁªÜ‰ø°ÊÅØÔºåÂπ∂Á°Æ‰øùÊÇ®ÁöÑÁéØÂ¢ÉÈÖçÁΩÆÊ≠£Á°Æ„ÄÇ")
        st.info("Â∞ùËØïËß£ÂÜ≥ÊñπÊ°àÔºö1. Ê£ÄÊü•NumPyÁâàÊú¨ (Âª∫ËÆÆ < 2.0)„ÄÇ 2. ÈáçÊñ∞ÂÆâË£ÖÁõ∏ÂÖ≥Â∫ì„ÄÇ")
        st.stop()
    # st.stop() should prevent execution from reaching here if an exception occurred.
    # Adding a fallback return or raise for extreme defensiveness, though st.stop() should suffice.
    # This line should ideally not be reached if st.stop() works as intended.
    st.error("SpaCyÊ®°ÂûãÂä†ËΩΩÂ§±Ë¥•ÂêéÔºåËÑöÊú¨ÊÑèÂ§ñÁªßÁª≠ÊâßË°å„ÄÇËØ∑Ê£ÄÊü•ÈîôËØØÊó•Âøó„ÄÇ")
    return None # Should not be reached if st.stop() is effective

# nlp_spacy = load_spacy_model() # This global instance might need to be re-evaluated or removed if model is chosen dynamically per task
# For NER, we will call load_spacy_model with the selected model name.

# --- Sample Data and Classifier Training (Minimalistic) ---
# Ê≥®ÊÑèÔºöËøôÊòØ‰∏Ä‰∏™ÈùûÂ∏∏Âü∫Á°ÄÁöÑÂàÜÁ±ªÂô®Ôºå‰ªÖÁî®‰∫éÊºîÁ§∫„ÄÇÂÆûÈôÖÂ∫îÁî®‰∏≠ÈúÄË¶ÅÊõ¥Â§ß„ÄÅÊõ¥ÂùáË°°ÁöÑÊï∞ÊçÆÈõÜÂíåÊõ¥Â§çÊùÇÁöÑÊ®°Âûã„ÄÇ
classification_texts = [
    "ÂõΩË∂≥Âú®‰∏ñÁïåÊùØÈ¢ÑÈÄâËµõ‰∏≠ÂèñÂæóÂÖ≥ÈîÆËÉúÂà©Ôºå‰ΩìËÇ≤Ëø∑Ê¨¢Ê¨£ÈºìËàû„ÄÇ",
    "ÊúÄÊñ∞ÁöÑÂÖ®ÁêÉÁªèÊµéÊä•ÂëäÊåáÂá∫ÔºåËÇ°Â∏ÇÈù¢‰∏¥ÂõûË∞ÉÈ£éÈô©ÔºåË¥¢ÁªèÈ¢ÜÂüüÈúÄË∞®ÊÖé„ÄÇ",
    "ÊüêÊòéÊòüÊñ∞ÁîµÂΩ±Á•®ÊàøÂ§ßÂçñÔºåÂºïÂèëÂ®±‰πêÁïåÁÉ≠ËÆÆ„ÄÇ",
    "‰∫∫Â∑•Êô∫ËÉΩÊäÄÊúØÂèñÂæóÊñ∞Á™ÅÁ†¥ÔºåÁßëÊäÄÂÖ¨Âè∏Á∫∑Á∫∑Â∏ÉÂ±Ä„ÄÇ",
    "Â••Ëøê‰ºö‰∏≠ÂõΩ‰ª£Ë°®Âõ¢ÂÜçÊ∑ªÈáëÁâåÔºå‰ΩìËÇ≤ÂÅ•ÂÑøË°®Áé∞Âá∫Ëâ≤„ÄÇ",
    "Â§ÆË°åÂÆ£Â∏ÉÈôçÊÅØÔºåÊó®Âú®Âà∫ÊøÄÁªèÊµéÂ¢ûÈïøÔºåË¥¢ÁªèÂ∏ÇÂú∫ÂèçÂ∫îÁßØÊûÅ„ÄÇ",
    "Âπ¥Â∫¶Èü≥‰πêÁõõÂÖ∏ËêΩ‰∏ãÂ∏∑ÂπïÔºåÂ§ö‰ΩçÊ≠åÊâãËé∑Â•ñÔºåÂ®±‰πêÊ∞õÂõ¥ÊµìÂéö„ÄÇ",
    "Êñ∞ÂûãËäØÁâáÂèëÂ∏ÉÔºåËÆ°ÁÆóËÉΩÂäõÂ§ßÂπÖÊèêÂçáÔºåÁßëÊäÄÂàõÊñ∞Ê∞∏Êó†Ê≠¢Â¢É„ÄÇ"
]
classification_labels = ["‰ΩìËÇ≤", "Ë¥¢Áªè", "Â®±‰πê", "ÁßëÊäÄ", "‰ΩìËÇ≤", "Ë¥¢Áªè", "Â®±‰πê", "ÁßëÊäÄ"]

@st.cache_resource # Cache the trained classifier
def train_text_classifier(texts, labels, classifier_choice="MultinomialNB"):
    """ËÆ≠ÁªÉ‰∏Ä‰∏™ÁÆÄÂçïÁöÑÊñáÊú¨ÂàÜÁ±ªÂô®ÔºåÂèØÈÄâÊã©ÂàÜÁ±ªÁÆóÊ≥ï„ÄÇ"""
    
    selected_classifier = None
    if classifier_choice == "MultinomialNB":
        selected_classifier = MultinomialNB()
    elif classifier_choice == "LogisticRegression":
        selected_classifier = LogisticRegression(random_state=42, solver='liblinear')
    elif classifier_choice == "LinearSVC":
        selected_classifier = LinearSVC(random_state=42, dual='auto')
    else:
        st.error(f"Êú™Áü•ÁöÑÂàÜÁ±ªÂô®ÈÄâÈ°π: {classifier_choice}ÔºåÂ∞Ü‰ΩøÁî®ÈªòËÆ§ÁöÑMultinomialNB„ÄÇ")
        selected_classifier = MultinomialNB()

    # ‰ΩøÁî®jiebaËøõË°å‰∏≠ÊñáÂàÜËØçÁöÑTF-IDFÂêëÈáèÂåñÂô®
    model = Pipeline([
        ('tfidf', TfidfVectorizer(tokenizer=lambda x: list(jieba.cut(x)))), 
        ('clf', selected_classifier)
    ])
    model.fit(texts, labels)
    return model

# classifier = train_text_classifier(classification_texts, classification_labels) # Deferred to be dynamic based on selection
class_names = sorted(list(set(classification_labels))) # Ëé∑ÂèñÂîØ‰∏ÄÁöÑÁ±ªÂà´ÂêçÂπ∂ÊéíÂ∫è

# --- Matplotlib Font Fix for Chinese ---
# For best results, place a Chinese font file (e.g., SimHei.ttf or NotoSansCJKsc-Regular.otf)
# in the 'nlpp/' directory alongside app.py.
CHINESE_FONT_FILENAME = "NotoSansCJKsc-Regular.otf" # Or your chosen font file

def setup_matplotlib_font():
    try:
        font_path = os.path.join(os.path.dirname(__file__), CHINESE_FONT_FILENAME)
        
        font_successfully_set = False
        if os.path.exists(font_path):
            # Use the font file directly if it exists
            matplotlib.font_manager.fontManager.addfont(font_path)
            font_prop = matplotlib.font_manager.FontProperties(fname=font_path)
            matplotlib.rcParams['font.family'] = font_prop.get_name()
            # Prepend to sans-serif list as well
            matplotlib.rcParams['font.sans-serif'] = [font_prop.get_name()] + matplotlib.rcParams.get('font.sans-serif', [])
            # st.sidebar.info(f"Â∑≤ÊàêÂäüÂä†ËΩΩÂ≠ó‰Ωì: {font_prop.get_name()} (Êù•Ëá™Êñá‰ª∂: {CHINESE_FONT_FILENAME})")
            font_successfully_set = True
        else:
            # If local font file not found, try a list of common Chinese font family names
            # These names must be known to the system's Matplotlib font manager
            common_chinese_fonts = [
                'WenQuanYi Micro Hei', 'Noto Sans CJK SC', 'SimHei', 
                'Source Han Sans SC', 'AR PL UKai CN', 'AR PL UMing CN', 
                'WenQuanYi Zen Hei', 'DejaVu Sans Fallback' 
            ]
            
            original_sans_serif = list(matplotlib.rcParams.get('font.sans-serif', [])) # Make a mutable copy
            
            # Check if any of the common Chinese fonts are available and set it as the primary family
            font_manager = matplotlib.font_manager.fontManager
            available_font_names = [f.name for f in font_manager.ttflist]
            
            for font_name in common_chinese_fonts:
                if font_name in available_font_names:
                    matplotlib.rcParams['font.family'] = font_name
                    # Ensure this font is also at the start of the sans-serif list
                    if font_name in original_sans_serif:
                        original_sans_serif.remove(font_name)
                    matplotlib.rcParams['font.sans-serif'] = [font_name] + original_sans_serif
                    # st.sidebar.info(f"Â∑≤ÊàêÂäüÂä†ËΩΩÁ≥ªÁªüÂ≠ó‰Ωì: {font_name}")
                    font_successfully_set = True
                    break
            
            if not font_successfully_set:
                st.sidebar.warning(
                    f"Êú™Âú® '{font_path}' ÊâæÂà∞Â≠ó‰ΩìÊñá‰ª∂ '{CHINESE_FONT_FILENAME}'Ôºå‰∏îÊú™ËÉΩ‰ªéÂ∏∏ËßÅÁ≥ªÁªüÂ≠ó‰ΩìÂàóË°®‰∏≠Âä†ËΩΩ‰∏≠ÊñáÂ≠ó‰Ωì„ÄÇ"
                    f"ÂõæË°®‰∏≠ÁöÑ‰∏≠ÊñáÂèØËÉΩÊó†Ê≥ïÊ≠£Á°ÆÊòæÁ§∫„ÄÇËØ∑ÊîæÁΩÆ‰∏Ä‰∏™TTF‰∏≠ÊñáÂ≠ó‰Ωì (Â¶Ç SimHei.ttf) Âà∞ 'nlpp/' ÁõÆÂΩï‰∏ãÂπ∂ÈáçÂêØÂ∫îÁî®„ÄÇ"
                )

        matplotlib.rcParams['axes.unicode_minus'] = False  # Ensure minus sign displays correctly

        # Dark theme adjustments for Matplotlib
        matplotlib.rcParams['text.color'] = '#E5E7EB'       # Light gray for text
        matplotlib.rcParams['axes.labelcolor'] = '#D1D5DB'  # Slightly darker for labels
        matplotlib.rcParams['xtick.color'] = '#9CA3AF'      # Muted for ticks
        matplotlib.rcParams['ytick.color'] = '#9CA3AF'
        matplotlib.rcParams['axes.edgecolor'] = '#4B5563'   # Border color for axes
        matplotlib.rcParams['figure.facecolor'] = 'none'    # Transparent figure background
        matplotlib.rcParams['axes.facecolor'] = 'none'      # Transparent axes background
        matplotlib.rcParams['savefig.transparent'] = True   # Ensure saved figures are transparent

    except Exception as e:
        st.sidebar.error(f"ÈÖçÁΩÆMatplotlib‰∏≠ÊñáÂ≠ó‰ΩìÊó∂Âá∫Èîô: {e}")

setup_matplotlib_font() # Call the function to set the font

# --- Plotting Functions (Refactored and Enhanced) ---

def plot_scatter_clusters(ax, X_reduced, labels, cluster_model_name,
                          colormap='viridis', marker_size=50, marker_alpha=0.7,
                          marker_styles_enabled=False,
                          bg_color='rgba(0,0,0,0)', show_grid=True, grid_color='#4B5563'):
    """ÁªòÂà∂ËÅöÁ±ªÁªìÊûúÁöÑÊï£ÁÇπÂõæÔºåÂÖ∑ÊúâÂ¢ûÂº∫ÁöÑÂèØËßÜÂåñÈÄâÈ°π„ÄÇ"""
    ax.clear() # Clear previous plot on the axis
    ax.set_facecolor(bg_color)

    unique_labels = sorted(list(set(labels)))
    is_dbscan_with_outliers = cluster_model_name == "DBSCAN" and -1 in unique_labels
    
    current_cmap = plt.get_cmap(colormap)
    
    plot_labels_for_colors = [l for l in unique_labels if l != -1] if is_dbscan_with_outliers else unique_labels
    if not plot_labels_for_colors: # Handle cases with only noise or no clusters
        plot_labels_for_colors = unique_labels # Avoid error if only noise points
        
    num_plot_clusters = max(1, len(plot_labels_for_colors)) # Ensure at least 1 for color mapping
    colors_for_plot = current_cmap(np.linspace(0, 1, num_plot_clusters))
    color_map_dict = {label: colors_for_plot[i] for i, label in enumerate(plot_labels_for_colors)}

    marker_options = ['o', 's', '^', 'D', 'v', '<', '>', 'p', '*', 'H', 'X']
    legend_elements = []

    for i, label_val in enumerate(unique_labels):
        idx = (labels == label_val)
        current_marker = marker_options[i % len(marker_options)] if marker_styles_enabled else 'o'
        
        if label_val == -1 and is_dbscan_with_outliers:
            ax.scatter(X_reduced[idx, 0], X_reduced[idx, 1], color='gray', label='Á¶ªÁæ§ÁÇπ', 
                       alpha=marker_alpha, marker='x', s=marker_size)
            legend_elements.append(matplotlib.lines.Line2D([0], [0], marker='x', color='w', label='Á¶ªÁæ§ÁÇπ', markerfacecolor='gray', markersize=10, linestyle='None'))
        elif X_reduced[idx].shape[0] > 0 : # Ensure there are points in the cluster
            cluster_color = color_map_dict.get(label_val, current_cmap(0.0)) # Default color if label somehow not in dict
            ax.scatter(X_reduced[idx, 0], X_reduced[idx, 1], color=cluster_color, 
                       label=f'ËÅöÁ±ª {label_val}', alpha=marker_alpha, 
                       marker=current_marker, edgecolors='w', s=marker_size)
            legend_elements.append(matplotlib.lines.Line2D([0], [0], marker=current_marker, color='w', label=f'ËÅöÁ±ª {label_val}', markerfacecolor=cluster_color, markersize=10))

    if legend_elements:
        ax.legend(handles=legend_elements, title="Âõæ‰æã", bbox_to_anchor=(1.05, 1), loc='upper left')
    
    ax.set_xlabel("Component 1", fontsize=10)
    ax.set_ylabel("Component 2", fontsize=10)
    
    if show_grid:
        ax.grid(True, color=grid_color, linestyle='--', alpha=0.5)
    else:
        ax.grid(False)
    plt.tight_layout(rect=[0, 0, 0.85, 1]) # Adjust layout to make space for legend

def plot_dynamic_dendrogram(ax, tfidf_matrix_dense, linkage_method, metric, 
                            orientation='top', color_threshold=None):
    """ÁªòÂà∂Ê†ëÁä∂ÂõæÔºàÊÅ¢Â§çÂà∞ËæÉÁÆÄÂçïÁâàÊú¨Ôºâ„ÄÇ"""
    ax.clear()
    ax.set_facecolor('none') # Set transparent background for axes

    if tfidf_matrix_dense is None or tfidf_matrix_dense.shape[0] < 2:
        ax.text(0.5, 0.5, "Êï∞ÊçÆ‰∏çË∂≥‰ª•ÁîüÊàêÊ†ëÁä∂Âõæ", ha="center", va="center", transform=ax.transAxes)
        return

    try:
        linkage_matrix_val = linkage(tfidf_matrix_dense, method=linkage_method, metric=metric)
        
        # Simplified dendrogram plotting, closer to original implicit behavior
        # Default truncation and leaf display will be handled by scipy if not specified, or use simple defaults.
        p_dendro = min(30, tfidf_matrix_dense.shape[0])
        doc_labels = None # No detailed labels by default in this simplified version
        if tfidf_matrix_dense.shape[0] <= p_dendro + 10: # Basic heuristic for showing some labels if few docs
             doc_labels = [f"Êñá{i}" for i in range(tfidf_matrix_dense.shape[0])]
        
        dendrogram(
            linkage_matrix_val, 
            ax=ax, 
            orientation=orientation, 
            truncate_mode='lastp', # A common default for readability 
            p=p_dendro,              # A common default for readability
            leaf_rotation=90. if orientation in ['top', 'bottom'] else 0., 
            leaf_font_size=8., 
            show_contracted=True,
            labels=doc_labels, # Simplified labels
            color_threshold=color_threshold # Retain color threshold if provided
        )
        
        ax.set_title(f"Â±ÇÊ¨°ËÅöÁ±ªÊ†ëÁä∂Âõæ ({linkage_method} linkage)", fontsize=14)
        if orientation in ['top', 'bottom']:
            ax.set_xlabel("ÊñáÊ°£Á¥¢ÂºïÊàñËÅöÁ±ª", fontsize=10)
            ax.set_ylabel("Ë∑ùÁ¶ª/Â∑ÆÂºÇÂ∫¶", fontsize=10)
        else:
            ax.set_ylabel("ÊñáÊ°£Á¥¢ÂºïÊàñËÅöÁ±ª", fontsize=10)
            ax.set_xlabel("Ë∑ùÁ¶ª/Â∑ÆÂºÇÂ∫¶", fontsize=10)
        
        if color_threshold and color_threshold > 0:
             if orientation in ['top', 'bottom']:
                ax.axhline(y=color_threshold, c='grey', lw=1, linestyle='dashed')
             else: # left, right
                ax.axvline(x=color_threshold, c='grey', lw=1, linestyle='dashed')
        plt.tight_layout()
    except Exception as e_dendro:
        st.error(f"ÁîüÊàêÊ†ëÁä∂ÂõæÊó∂Âá∫Èîô: {e_dendro}")
        ax.text(0.5, 0.5, f"ÁîüÊàêÊ†ëÁä∂ÂõæÈîôËØØ: {e_dendro}", ha="center", va="center", transform=ax.transAxes, color='red')

# --- Homepage Rendering Function ---
def render_homepage():
    st.markdown("""
    <div style="text-align: center; padding-top: 1rem; padding-bottom: 1rem;">
        <span style="font-size: 4.5em; line-height: 1;">üöÄ</span>
        <h1 style="font-size: 3.2em; font-weight: 700; color: #F9FAFB; margin-top: 0.5rem; margin-bottom: 0.75rem; letter-spacing: -0.5px;">
            ‰∏≠ÊñáNLPÊô∫ËÉΩÂàÜÊûêÂπ≥Âè∞
        </h1>
        <p style="font-size: 1.3em; color: #D1D5DB; max-width: 750px; margin: 0 auto 1.5rem auto; line-height: 1.7;">
            ‰∏ÄÁ´ôÂºèÊª°Ë∂≥ÊÇ®ÁöÑ‰∏≠ÊñáËá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÈúÄÊ±Ç„ÄÇÊé¢Á¥¢ÊñáÊú¨ÁöÑÊ∑±Â±Ç‰ª∑ÂÄºÔºå‰ªéÊô∫ËÉΩÂàÜËØçÂà∞È´òÁ∫ßËÅöÁ±ªÂàÜÊûêÔºå‰ΩìÈ™åÂâçÊ≤øAIÊäÄÊúØ„ÄÇ
        </p>
    </div>
    """, unsafe_allow_html=True)

    st.markdown("<hr style='border-top: 1px solid #374151; margin-top: 1rem; margin-bottom: 2rem;'>", unsafe_allow_html=True)
    
    st.markdown("<h2 style='text-align: center; font-size: 2.2em; font-weight: 600; color: #F3F4F6; margin-top: 2rem; margin-bottom: 2.5rem;'>Ê†∏ÂøÉÂäüËÉΩ‰∏ÄËßà ‚ú®</h2>", unsafe_allow_html=True)

    col1, col2 = st.columns(2)

    with col1:
        st.markdown("""
        <div class="feature-card">
            <h3>üìù Êô∫ËÉΩÂàÜËØç & ËØçÈ¢ë</h3>
            <p>Á≤æÂáÜÂàáÂàÜ‰∏≠ÊñáÊñáÊú¨ÔºåÁªüËÆ°È´òÈ¢ëËØçÊ±áÔºåÂπ∂ÁîüÊàêÁõ¥ËßÇÁöÑËØç‰∫ëÂõæÂíåËØçÈ¢ëÁªüËÆ°Âõæ„ÄÇÊîØÊåÅJiebaÂíåSpaCyÂºïÊìéÔºåÊ∑±ÂÖ•Ê¥ûÂØüÊñáÊú¨ÊûÑÊàê„ÄÇ</p>
        </div>
        """, unsafe_allow_html=True)
        
        st.markdown("""
        <div class="feature-card">
            <h3>üìä ‰∏≠ÊñáÊñáÊú¨ÂàÜÁ±ª</h3>
            <p>Â∞ÜÊñáÊú¨Ëá™Âä®ÂΩíÁ±ªÂà∞È¢ÑÂÆö‰πâ‰∏ªÈ¢òÔºàÂ¶Ç‰ΩìËÇ≤„ÄÅË¥¢Áªè„ÄÅÂ®±‰πê„ÄÅÁßëÊäÄÔºâ„ÄÇÊîØÊåÅÂ§öÁßçÁªèÂÖ∏ÂàÜÁ±ªÁÆóÊ≥ïÔºåÊèê‰æõÂêÑÁ±ªÂà´Ê¶ÇÁéáÂàÜÂ∏ÉÔºåËæÖÂä©ÂÜ≥Á≠ñ„ÄÇ</p>
        </div>
        """, unsafe_allow_html=True)

    with col2:
        st.markdown("""
        <div class="feature-card">
            <h3>üëÅÔ∏è‚Äçüó®Ô∏è ÂëΩÂêçÂÆû‰ΩìËØÜÂà´ (NER)</h3>
            <p>‰ªéÊñáÊú¨‰∏≠Ëá™Âä®ËØÜÂà´Âπ∂ÂàÜÁ±ªÂÖ≥ÈîÆÂÆû‰ΩìÔºà‰∫∫Âêç„ÄÅÂú∞Âêç„ÄÅÊú∫ÊûÑÂêçÁ≠âÔºâ„ÄÇÂèØÁÅµÊ¥ªÈÄâÊã©‰∏çÂêåËßÑÊ®°ÁöÑSpaCyÈ¢ÑËÆ≠ÁªÉÊ®°ÂûãÔºåÊª°Ë∂≥‰∏çÂêåÁ≤æÂ∫¶ÈúÄÊ±Ç„ÄÇ</p>
        </div>
        """, unsafe_allow_html=True)

        st.markdown("""
        <div class="feature-card">
            <h3>üß© ÊñáÊú¨ËÅöÁ±ªÂàÜÊûê</h3>
            <p>Êó†ÁõëÁù£Âú∞Â∞ÜÁõ∏‰ººÊñáÊú¨Ëá™Âä®ÂàÜÁªÑÔºåÊè≠Á§∫Êï∞ÊçÆÈõÜ‰∏≠ÁöÑÊΩúÂú®ÁªìÊûÑ‰∏éËØùÈ¢ò„ÄÇÊèê‰æõÂ§öÁßçËÅöÁ±ªÁÆóÊ≥ïÂíå‰∏∞ÂØåÁöÑÂèØËßÜÂåñÂ∑•ÂÖ∑ÔºåÂä©ÂäõÊé¢Á¥¢ÊÄßÊï∞ÊçÆÂàÜÊûê„ÄÇ</p>
        </div>
        """, unsafe_allow_html=True)
    
    st.markdown("<hr style='border-top: 1px solid #374151; margin-top: 3rem; margin-bottom: 1.5rem;'><p style='text-align: center; font-size: 1.1em; color: #9CA3AF;'>ËØ∑‰ªéÂ∑¶‰æßÂØºËà™Ê†èÈÄâÊã©‰∏ÄÈ°πÂäüËÉΩÂºÄÂßãÊÇ®ÁöÑÂàÜÊûê‰πãÊóÖÔºÅ</p>", unsafe_allow_html=True)


# nlp_spacy = load_spacy_model() # This global instance might need to be re-evaluated or removed if model is chosen dynamically per task
# For NER, we will call load_spacy_model with the selected model name.

# --- UI Sections ---
# The following st.title and st.markdown are removed to avoid redundancy with render_homepage() on the homepage.
# For other pages, specific headers like "1. ËæìÂÖ•ÊñáÊú¨" are used.
# st.title("‰∏≠ÊñáNLPÊô∫ËÉΩÂàÜÊûêÂπ≥Âè∞ ü§ñ") 
# st.markdown("""Ê¨¢Ëøé‰ΩøÁî®Êú¨Âπ≥Âè∞ÔºÅËØ∑Âú®‰∏ãÊñπÈÄâÊã©ÊÇ®Ë¶ÅÊâßË°åÁöÑËá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜ‰ªªÂä°„ÄÇ
# ÊÇ®ÂèØ‰ª•Áõ¥Êé•Á≤òË¥¥ÊñáÊú¨Êàñ‰∏ä‰º†TXTÊñá‰ª∂ËøõË°åÂàÜÊûê„ÄÇ
# """)

# --- Sidebar for Navigation ---
st.sidebar.header("üß≠ ÂØºËà™")
analysis_options = [
    "üè† ‰∏ªÈ°µ",
    "üìù ‰∏≠ÊñáÂàÜËØç", 
    "üëÅÔ∏è‚Äçüó®Ô∏è ÂëΩÂêçÂÆû‰ΩìËØÜÂà´", 
    "üìä ‰∏≠ÊñáÊñáÊú¨ÂàÜÁ±ª", 
    "üß© ÊñáÊú¨ËÅöÁ±ªÂàÜÊûê"
]
selected_analysis = st.sidebar.radio("ÈÄâÊã©ÂäüËÉΩ:", analysis_options)

# --- Input Area ---
# Moved the condition for showing input area outside homepage
if selected_analysis != "üè† ‰∏ªÈ°µ":
    st.header("‚å®Ô∏è 1. ËæìÂÖ•ÊñáÊú¨")
    input_method = st.radio("ÈÄâÊã©ËæìÂÖ•ÊñπÂºè:", ("Á≤òË¥¥ÊñáÊú¨", "‰∏ä‰º†TXTÊñá‰ª∂"), horizontal=True, key="input_method_radio")

    raw_texts = []  # Áî®‰∫éÂ≠òÂÇ®ÊâÄÊúâÂæÖÂ§ÑÁêÜÁöÑÊñáÊú¨Ë°å

    if input_method == "Á≤òË¥¥ÊñáÊú¨":
        text_area_input = st.text_area("Âú®Ê≠§Â§ÑÁ≤òË¥¥ÊñáÊú¨ÔºàÂØπ‰∫éËÅöÁ±ªÔºåÊØèË°å‰ª£Ë°®‰∏Ä‰∏™Áã¨Á´ãÊñáÊ°£Ôºâ:", "", height=200, key="paste_area")
        if text_area_input:
            raw_texts = [line.strip() for line in text_area_input.split('\n') if line.strip()]
    elif input_method == "‰∏ä‰º†TXTÊñá‰ª∂":
        uploaded_files = st.file_uploader("‰∏ä‰º†‰∏Ä‰∏™ÊàñÂ§ö‰∏™TXTÊñá‰ª∂ (UTF-8ÁºñÁ†Å):", type=["txt"], accept_multiple_files=True, key="file_uploader")
        if uploaded_files:
            for uploaded_file in uploaded_files:
                try:
                    string_data = uploaded_file.read().decode("utf-8")
                    raw_texts.extend([line.strip() for line in string_data.split('\n') if line.strip()])
                except Exception as e:
                    st.error(f"ËØªÂèñÊñá‰ª∂ {uploaded_file.name} Â§±Ë¥•: {e}")

    # --- Example Data Button ---
    if not raw_texts:
        if st.button("ËΩΩÂÖ•Á§∫‰æãÊï∞ÊçÆËøõË°åÊµãËØï", key="load_example_button"):
            if selected_analysis == "üß© ÊñáÊú¨ËÅöÁ±ªÂàÜÊûê":
                raw_texts = [
                    "Ê∑±Â∫¶Â≠¶‰π†ÊòØÊú∫Âô®Â≠¶‰π†ÁöÑ‰∏Ä‰∏™ÈáçË¶ÅÂàÜÊîØÔºåÂÆÉÂú®ÂõæÂÉèËØÜÂà´È¢ÜÂüüÂèñÂæó‰∫ÜÂ∑®Â§ßÊàêÂäü„ÄÇ",
                    "Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÂÖ≥Ê≥®ËÆ°ÁÆóÊú∫Â¶Ç‰ΩïÁêÜËß£ÂíåÁîüÊàê‰∫∫Á±ªËØ≠Ë®ÄÔºåÂ∫îÁî®ÂπøÊ≥õ„ÄÇ",
                    "Êú∫Âô®Â≠¶‰π†ÁÆóÊ≥ïÔºåÂ¶ÇÊîØÊåÅÂêëÈáèÊú∫ÂíåÂÜ≥Á≠ñÊ†ëÔºåÂ∏∏Áî®‰∫éÊï∞ÊçÆÊåñÊéò‰ªªÂä°„ÄÇ",
                    "ËãπÊûúÂÖ¨Âè∏ÊúÄËøëÂèëÂ∏É‰∫ÜÊñ∞Ê¨æiPhoneÔºåÈÖçÂ§á‰∫ÜÊõ¥Âº∫Â§ßÁöÑAÁ≥ªÂàó‰ªøÁîüËäØÁâá„ÄÇ",
                    "ÁâπÊñØÊãâÊòØÂÖ®ÁêÉÈ¢ÜÂÖàÁöÑÁîµÂä®Ê±ΩËΩ¶Âà∂ÈÄ†ÂïÜÔºåÂÖ∂Ëá™Âä®È©æÈ©∂ÊäÄÊúØÂ§áÂèóÂÖ≥Ê≥®„ÄÇ",
                    "ÊúÄËøëÁöÑÈáëËûçÂ∏ÇÂú∫Ê≥¢Âä®ËæÉÂ§ßÔºåÊäïËµÑËÄÖÂú®ËøõË°åËÇ°Á•®‰∫§ÊòìÊó∂Â∫î‰øùÊåÅË∞®ÊÖé„ÄÇ",
                    "‰∏≠ÂõΩÂõΩÂÆ∂Ë∂≥ÁêÉÈòüÊ≠£Âú®ÁßØÊûÅÂ§áÊàòÂç≥Â∞ÜÂà∞Êù•ÁöÑ‰∫öÊ¥≤ÊùØÈ¢ÑÈÄâËµõ„ÄÇ",
                    "NBAÁØÆÁêÉËÅîËµõÂ∏∏ËßÑËµõÊøÄÊàòÊ≠£ÈÖ£ÔºåÂêÑÊîØÁêÉÈòü‰∏∫Â≠£ÂêéËµõÂêçÈ¢ùÂ±ïÂºÄÊøÄÁÉà‰∫âÂ§∫„ÄÇ"
                ]
                st.toast("Â∑≤Âä†ËΩΩËÅöÁ±ªÁ§∫‰æãÊï∞ÊçÆ„ÄÇ", icon="üìÑ")
            elif selected_analysis == "üìä ‰∏≠ÊñáÊñáÊú¨ÂàÜÁ±ª":
                raw_texts = ["ÊúÄÊñ∞ÁöÑ‰ΩìËÇ≤Êñ∞ÈóªÊä•ÈÅì‰∫ÜÊò®ÊôöÁöÑË∂≥ÁêÉÊØîËµõÁªìÊûú„ÄÇ"]
                st.toast("Â∑≤Âä†ËΩΩÂàÜÁ±ªÁ§∫‰æãÊï∞ÊçÆ„ÄÇ", icon="üìÑ")
            else: # For word segmentation and NER
                raw_texts = ["ÊàëÁà±Âåó‰∫¨Â§©ÂÆâÈó®ÔºåÂ§©ÂÆâÈó®‰∏äÂ§™Èò≥Âçá„ÄÇ‰ºüÂ§ßÈ¢ÜË¢ñÊØõ‰∏ªÂ∏≠ÔºåÊåáÂºïÊàë‰ª¨ÂêëÂâçËøõ„ÄÇ"]
                st.toast("Â∑≤Âä†ËΩΩÈÄöÁî®Á§∫‰æãÊï∞ÊçÆ„ÄÇ", icon="üìÑ")
else: # if selected_analysis == "üè† ‰∏ªÈ°µ":
    raw_texts = [] # Ensure raw_texts is empty or not used for homepage


# --- Process and Display --- 
current_text_to_process = "" # Áî®‰∫éÂçïÊñáÊú¨ÂàÜÊûê‰ªªÂä°
if selected_analysis != "üè† ‰∏ªÈ°µ" and raw_texts: # Ensure this logic only runs for analysis pages with text
    current_text_to_process = raw_texts[0]
    if len(raw_texts) > 1 and selected_analysis not in ["üß© ÊñáÊú¨ËÅöÁ±ªÂàÜÊûê"]:
        st.info(f"Ê£ÄÊµãÂà∞ {len(raw_texts)} ÊÆµÊñáÊú¨„ÄÇÂØπ‰∫é'{selected_analysis}'ÔºåÈªòËÆ§Â§ÑÁêÜÁ¨¨‰∏ÄÊÆµ„ÄÇÂ¶ÇÈúÄÊâπÈáèÂ§ÑÁêÜÔºåËØ∑ÈÄâÊã©'ÊñáÊú¨ËÅöÁ±ªÂàÜÊûê'ÊàñÂàÜÂà´Êìç‰Ωú„ÄÇ", icon="‚ÑπÔ∏è")

if selected_analysis != "üè† ‰∏ªÈ°µ": # Only add divider if not on homepage
    st.divider()

# --- Main logic for different analyses ---
if selected_analysis == "üè† ‰∏ªÈ°µ":
    render_homepage()
    # Footer for homepage can be part of render_homepage or here
    # st.sidebar.markdown("--- "*10) # This is already at the end of the script, keep it there
    # st.sidebar.info("¬© 2024 ‰∏≠ÊñáNLPÊô∫ËÉΩÂàÜÊûêÂπ≥Âè∞")

elif raw_texts: # For other analysis options, only proceed if raw_texts exist
    st.header("üîç 2. Êü•ÁúãÂàÜÊûêÁªìÊûú")

    # 1. Chinese Word Segmentation
    if selected_analysis == "üìù ‰∏≠ÊñáÂàÜËØç":
        if current_text_to_process:
            st.subheader("‚úÇÔ∏è ‰∏≠ÊñáÂàÜËØçÁªìÊûú")
            
            # --- Model Selection for Word Segmentation ---
            segmentation_model_options = ["Jieba", "SpaCy"]
            selected_segmentation_model = st.selectbox("ÈÄâÊã©ÂàÜËØçÂºïÊìé:", segmentation_model_options, key="segmentation_model_selector")
            st.write("---ÂéüÂßãÊñáÊú¨---") # Changed from st.write("**ÂéüÂßãÊñáÊú¨:**", current_text_to_process)
            st.text(current_text_to_process) # Using st.text for better block display of original text
            st.write("---ÂàÜËØçÁªìÊûú---")

            with st.spinner(f"Ê≠£Âú®‰ΩøÁî® {selected_segmentation_model} ËøõË°åÂàÜËØç..."):
                processed_tokens_for_cloud = []
                if selected_segmentation_model == "Jieba":
                    seg_list_jieba = list(jieba.cut(current_text_to_process))
                    st.info(" / ".join(seg_list_jieba))
                    processed_tokens_for_cloud = seg_list_jieba
                    if seg_list_jieba:
                        st.markdown("---")
                        st.markdown("##### üìä Top 15 ËØçÈ¢ëÁªüËÆ° (Jieba)")
                        word_counts = pd.Series(seg_list_jieba).value_counts().nlargest(15)
                        if not word_counts.empty:
                            word_counts_df = word_counts.reset_index()
                            word_counts_df.columns = ['ËØçËØ≠', 'È¢ëÁéá']
                            fig_bar_jieba = px.bar(word_counts_df, 
                                                 x='È¢ëÁéá', 
                                                 y='ËØçËØ≠', 
                                                 orientation='h', 
                                                 color='ËØçËØ≠', 
                                                 title="ËØçÈ¢ëÁªüËÆ° (Jieba)",
                                                 labels={'È¢ëÁéá':'È¢ëÁéá', 'ËØçËØ≠':'ËØçËØ≠'},
                                                 template="plotly_dark") # Apply dark theme
                            fig_bar_jieba.update_layout(yaxis={'categoryorder':'total ascending'}, showlegend=False)
                            st.plotly_chart(fig_bar_jieba, use_container_width=True)
                        else:
                            st.text("Êó†ÊúâÊïàËØçËØ≠ËøõË°åÁªüËÆ°„ÄÇ")

                elif selected_segmentation_model == "SpaCy":
                    nlp_segmentation_model = load_spacy_model("zh_core_web_sm") 
                    if nlp_segmentation_model:
                        doc_spacy = nlp_segmentation_model(current_text_to_process)
                        # Filter out punctuation and spaces for cleaner word cloud and frequency count
                        seg_list_spacy = [token.text for token in doc_spacy if not token.is_punct and not token.is_space and token.text.strip()]
                        st.info(" / ".join(seg_list_spacy))
                        processed_tokens_for_cloud = seg_list_spacy
                        if seg_list_spacy:
                            st.markdown("---")
                            st.markdown("##### üìä Top 15 ËØçÈ¢ëÁªüËÆ° (SpaCy)")
                            word_counts_spacy = pd.Series(seg_list_spacy).value_counts().nlargest(15)
                            if not word_counts_spacy.empty:
                                word_counts_spacy_df = word_counts_spacy.reset_index()
                                word_counts_spacy_df.columns = ['ËØçËØ≠', 'È¢ëÁéá']
                                fig_bar_spacy = px.bar(word_counts_spacy_df, 
                                                     x='È¢ëÁéá', 
                                                     y='ËØçËØ≠', 
                                                     orientation='h', 
                                                     color='ËØçËØ≠',
                                                     title="ËØçÈ¢ëÁªüËÆ° (SpaCy)",
                                                     labels={'È¢ëÁéá':'È¢ëÁéá', 'ËØçËØ≠':'ËØçËØ≠'},
                                                     template="plotly_dark") # Apply dark theme
                                fig_bar_spacy.update_layout(yaxis={'categoryorder':'total ascending'}, showlegend=False)
                                st.plotly_chart(fig_bar_spacy, use_container_width=True)
                            else:
                                st.text("Êó†ÊúâÊïàËØçËØ≠ËøõË°åÁªüËÆ°„ÄÇ")
                    else:
                        st.error("SpaCyÊ®°ÂûãÂä†ËΩΩÂ§±Ë¥•ÔºåÊó†Ê≥ïËøõË°åÂàÜËØç„ÄÇ")
                
                # --- Word Cloud Visualization (Common for both Jieba and SpaCy) ---
                if processed_tokens_for_cloud:
                    st.markdown("---")
                    st.markdown("##### ‚òÅÔ∏è ËØç‰∫ëÂõæ")
                    try:
                        # Try to get font path for WordCloud - simplified and more robust
                        font_path_wc = os.path.join(os.path.dirname(__file__), CHINESE_FONT_FILENAME)
                        
                        if not os.path.exists(font_path_wc):
                            st.warning(f"ËØç‰∫ëÊó†Ê≥ïÁîüÊàêÔºöÊú™Âú® 'nlpp/' ÁõÆÂΩï‰∏ãÊâæÂà∞‰∏≠ÊñáÂ≠ó‰ΩìÊñá‰ª∂ '{CHINESE_FONT_FILENAME}'„ÄÇËØ∑Á°Æ‰øùËØ•Êñá‰ª∂Â≠òÂú®„ÄÇ")
                            font_path_wc = None # Explicitly set to None if not found

                        if font_path_wc:
                            wordcloud_text = " ".join(processed_tokens_for_cloud)
                            if wordcloud_text.strip():
                                wc = WordCloud(
                                    font_path=font_path_wc, # Directly use the validated path
                                    width=800, 
                                    height=400, 
                                    background_color='white', # Wordcloud background itself
                                    colormap='viridis', # Example colormap, can be changed
                                    collocations=False 
                                ).generate(wordcloud_text)
                                
                                fig_wc, ax_wc = plt.subplots(figsize=(10,5))
                                ax_wc.imshow(wc, interpolation='bilinear')
                                ax_wc.axis("off")
                                # For dark theme Streamlit, ensure Matplotlib plot bg is transparent or matches
                                fig_wc.patch.set_alpha(0) # Make Matplotlib figure background transparent
                                ax_wc.patch.set_alpha(0)  # Make Matplotlib axes background transparent
                                st.pyplot(fig_wc)
                            else:
                                st.text("ÊñáÊú¨ÂÜÖÂÆπËøáÂ∞ëÊàñÊó†ÊúâÊïàËØçËØ≠ÔºåÊó†Ê≥ïÁîüÊàêËØç‰∫ë„ÄÇ")
                        # No else needed here, warning for font_path_wc=None is handled above
                                
                    except Exception as e_wc:
                        st.error(f"ÁîüÊàêËØç‰∫ëÊó∂Âá∫Èîô: {e_wc}")
        else:
            st.info("ËØ∑ËæìÂÖ•Êàñ‰∏ä‰º†ÊñáÊú¨‰ª•ËøõË°åÂàÜËØç„ÄÇ", icon="üëà")

    # 2. Named Entity Recognition (NER)
    elif selected_analysis == "üëÅÔ∏è‚Äçüó®Ô∏è ÂëΩÂêçÂÆû‰ΩìËØÜÂà´":
        if current_text_to_process:
            st.subheader("üè∑Ô∏è ÂëΩÂêçÂÆû‰ΩìËØÜÂà´ (NER) ÁªìÊûú")

            # --- Model Selection for NER ---
            ner_model_options = {
                "Â∞èÊ®°Âûã (zh_core_web_sm)": "zh_core_web_sm",
                "‰∏≠Á≠âÊ®°Âûã (zh_core_web_md)": "zh_core_web_md",
                "Â§ßÊ®°Âûã (zh_core_web_lg)": "zh_core_web_lg",
            }
            selected_ner_model_display_name = st.selectbox(
                "ÈÄâÊã©SpaCy NERÊ®°Âûã (Â§ßÊ®°ÂûãÈ¶ñÊ¨°Âä†ËΩΩËæÉÊÖ¢ÔºåÈúÄÂ∑≤‰∏ãËΩΩ):", 
                list(ner_model_options.keys()), 
                key="ner_model_selector"
            )
            selected_ner_model_name = ner_model_options[selected_ner_model_display_name]

            # Load the selected spaCy model for NER
            # The load_spacy_model function is cached, so it will be efficient after the first load of a model.
            nlp_ner_model = load_spacy_model(selected_ner_model_name)

            if nlp_ner_model is None:
                # Error handling is done in load_spacy_model, which calls st.stop()
                # So, execution should not reach here if a model fails to load.
                st.error("NERÊ®°ÂûãÂä†ËΩΩÂ§±Ë¥•ÔºåÊó†Ê≥ïÁªßÁª≠„ÄÇ") # Fallback, should not be seen normally
            else:
                with st.spinner(f"Ê≠£Âú®‰ΩøÁî® {selected_ner_model_display_name} ËøõË°åNERÂàÜÊûê..."):
                    st.write("**ÂéüÂßãÊñáÊú¨:**", current_text_to_process)
                    doc = nlp_ner_model(current_text_to_process)
                    
                    # Get labels from the current model's NER pipe
                    ner_labels = []
                    if nlp_ner_model.has_pipe("ner"):
                        ner_labels = list(nlp_ner_model.get_pipe("ner").labels)
                    
                    st.subheader("üî¶ È´ò‰∫ÆÂÆû‰Ωì:") # Added emoji and using subheader for emphasis
                    visualize_ner(doc, labels=ner_labels, show_table=False, title="", displacy_options={"colors": {"ORG": "#7DF9FF", "PERSON": "#FFC0CB", "LOC": "#LIGHTGREEN", "GPE":"#FFD700" }})
                    
                    if doc.ents:
                        st.markdown("#### üìã ËØÜÂà´Âà∞ÁöÑÂÆû‰ΩìÂàóË°®")
                        entities = [(ent.text, ent.label_) for ent in doc.ents]
                        df_ents = pd.DataFrame(entities, columns=["ÂÆû‰ΩìÊñáÊú¨", "ÂÆû‰ΩìÁ±ªÂûã"])
                        st.dataframe(df_ents, use_container_width=True)

                        if not df_ents.empty:
                            st.markdown("---")
                            st.markdown("##### üìä ÂÆû‰ΩìÁ±ªÂûãÁªüËÆ°")
                            entity_type_counts = df_ents["ÂÆû‰ΩìÁ±ªÂûã"].value_counts().reset_index()
                            entity_type_counts.columns = ['ÂÆû‰ΩìÁ±ªÂûã', 'Êï∞Èáè'] # Rename for Plotly
                            if not entity_type_counts.empty:
                                fig_ner_counts = px.bar(entity_type_counts, 
                                                        x='ÂÆû‰ΩìÁ±ªÂûã', 
                                                        y='Êï∞Èáè', 
                                                        color='ÂÆû‰ΩìÁ±ªÂûã',
                                                        title="ÂëΩÂêçÂÆû‰ΩìÁ±ªÂûãÂàÜÂ∏É",
                                                        labels={'ÂÆû‰ΩìÁ±ªÂûã':'ÂÆû‰ΩìÁ±ªÂûã', 'Êï∞Èáè':'Âá∫Áé∞Ê¨°Êï∞'},
                                                        template="plotly_dark") # Apply dark theme
                                fig_ner_counts.update_layout(xaxis_title="ÂÆû‰ΩìÁ±ªÂûã", yaxis_title="Êï∞Èáè", showlegend=True)
                                st.plotly_chart(fig_ner_counts, use_container_width=True)
                            else:
                                st.text("Êú™ËØÜÂà´Âà∞ÂèØÁªüËÆ°ÁöÑÂÆû‰ΩìÁ±ªÂûã„ÄÇ")
                    else:
                        st.info("Êú™Âú®Êú¨ÊÆµÊñáÊú¨‰∏≠ËØÜÂà´Âà∞ÂëΩÂêçÂÆû‰Ωì„ÄÇ")
        else:
            st.info("ËØ∑ËæìÂÖ•Êàñ‰∏ä‰º†ÊñáÊú¨‰ª•ËøõË°åNERÂàÜÊûê„ÄÇ", icon="üëà")

    # 3. Chinese Text Classification
    elif selected_analysis == "üìä ‰∏≠ÊñáÊñáÊú¨ÂàÜÁ±ª":
        if current_text_to_process:
            st.subheader("üéØ ‰∏≠ÊñáÊñáÊú¨ÂàÜÁ±ªÁªìÊûú")

            # --- Classifier Model Selection ---
            classifier_options = {
                "Êú¥Á¥†Ë¥ùÂè∂ÊñØ (MultinomialNB)": "MultinomialNB",
                "ÈÄªËæëÂõûÂΩí (LogisticRegression)": "LogisticRegression",
                "ÊîØÊåÅÂêëÈáèÊú∫ (LinearSVC)": "LinearSVC"
            }
            selected_classifier_display_name = st.selectbox(
                "ÈÄâÊã©ÂàÜÁ±ªÁÆóÊ≥ï:",
                list(classifier_options.keys()),
                key="classifier_selector"
            )
            selected_classifier_type = classifier_options[selected_classifier_display_name]

            # Train or load the selected classifier from cache
            classifier_model = train_text_classifier(classification_texts, classification_labels, classifier_choice=selected_classifier_type)

            if classifier_model:
                with st.spinner(f"Ê≠£Âú®‰ΩøÁî® {selected_classifier_display_name} ËøõË°åÊñáÊú¨ÂàÜÁ±ª..."):
                    st.write("**ÂàÜÊûêÊñáÊú¨:**", current_text_to_process[:200] + ("..." if len(current_text_to_process) > 200 else ""))
                    prediction = classifier_model.predict([current_text_to_process])[0]
                    
                    st.success(f"**È¢ÑÊµãÁ±ªÂà´:** {prediction}")

                    # Check if the classifier has predict_proba method
                    if hasattr(classifier_model, "predict_proba") and callable(classifier_model.predict_proba):
                        probabilities = classifier_model.predict_proba([current_text_to_process])[0]
                        prob_df = pd.DataFrame({'Á±ªÂà´': class_names, 'Ê¶ÇÁéá': probabilities})
                        prob_df = prob_df.sort_values(by='Ê¶ÇÁéá', ascending=False).reset_index(drop=True)
                        st.markdown("#### üìà ÂêÑÁ±ªÂà´Ê¶ÇÁéá")
                        st.dataframe(prob_df, use_container_width=True)

                        st.markdown("---")
                        # Gauge chart for the top prediction
                        if not prob_df.empty:
                            top_prediction_label = prob_df.iloc[0]['Á±ªÂà´']
                            top_prediction_prob = prob_df.iloc[0]['Ê¶ÇÁéá']
                            
                            st.markdown(f"##### üéØ ‰∏ªË¶ÅÈ¢ÑÊµãÁ±ªÂà´ ({top_prediction_label}) ÁΩÆ‰ø°Â∫¶")
                            fig_gauge = go.Figure(go.Indicator(
                                mode = "gauge+number",
                                value = top_prediction_prob * 100, # Convert to percentage
                                title = {'text': f"È¢ÑÊµã‰∏∫: {top_prediction_label}", 'font': {'color': "white"}},
                                gauge = {'axis': {'range': [None, 100]},
                                         'bar': {'color': "#636EFA"}, # Using a color from plotly_dark
                                         'steps' : [
                                             {'range': [0, 50], 'color': "rgba(255,255,255,0.1)"},
                                             {'range': [50, 80], 'color': "rgba(255,255,255,0.2)"}],
                                         'threshold' : {'line': {'color': "red", 'width': 4}, 'thickness': 0.75, 'value': 90}},
                                number = {'font': {'color': "white"}}
                                ))
                            fig_gauge.update_layout(height=300, margin=dict(t=50, b=50, l=50, r=50), template="plotly_dark") # Apply dark theme
                            st.plotly_chart(fig_gauge, use_container_width=True)

                        # Visualizing probabilities with Plotly bar chart
                        st.markdown("---")
                        st.markdown("##### üìä ÂêÑÁ±ªÂà´Ê¶ÇÁéáÂàÜÂ∏ÉÂõæ")
                        if not prob_df.empty:
                            fig_class_probs = px.bar(prob_df, 
                                                     x='Ê¶ÇÁéá', 
                                                     y='Á±ªÂà´', 
                                                     orientation='h',
                                                     color='Á±ªÂà´',
                                                     title="ÊñáÊú¨ÂàÜÁ±ªÂêÑÁ±ªÂà´Ê¶ÇÁéá",
                                                     labels={'Ê¶ÇÁéá':'È¢ÑÊµãÊ¶ÇÁéá', 'Á±ªÂà´':'ÊñáÊú¨Á±ªÂà´'},
                                                     template="plotly_dark") # Apply dark theme
                            fig_class_probs.update_layout(yaxis={'categoryorder':'total ascending'}, 
                                                      showlegend=False,
                                                      xaxis_ticksuffix="%") # Add % suffix to probability axis
                            # Convert probability to percentage for display on hover and ticks if desired
                            # fig_class_probs.update_traces(x=[val * 100 for val in prob_df['Ê¶ÇÁéá']])
                            st.plotly_chart(fig_class_probs, use_container_width=True)
                        else:
                            st.text("Êó†Ê¶ÇÁéá‰ø°ÊÅØÂèØ‰æõÂèØËßÜÂåñ„ÄÇ")
                    elif selected_classifier_type == "LinearSVC":
                        st.info(f"Ê≥®ÊÑè: {selected_classifier_display_name} Ê®°Âûã‰∏çÁõ¥Êé•Êèê‰æõÊ¶ÇÁéáËæìÂá∫„ÄÇÂÜ≥Á≠ñÂáΩÊï∞ÂÄºÂèØÁî®‰∫éËØÑ‰º∞ÁΩÆ‰ø°Â∫¶Ôºå‰ΩÜÊ≠§Â§ÑÊú™ÊòæÁ§∫„ÄÇ")
                    else:
                        st.warning(f"ÂΩìÂâçÈÄâÊã©ÁöÑÂàÜÁ±ªÂô® {selected_classifier_display_name} ‰∏çÊîØÊåÅÊ¶ÇÁéáËæìÂá∫„ÄÇ")
            else:
                st.error("ÂàÜÁ±ªÂô®Ê®°ÂûãÊú™ËÉΩÊàêÂäüÂä†ËΩΩÊàñËÆ≠ÁªÉ„ÄÇ")
                
        else:
            st.info("ËØ∑ËæìÂÖ•Êàñ‰∏ä‰º†ÊñáÊú¨‰ª•ËøõË°åÊñáÊú¨ÂàÜÁ±ª„ÄÇÂè™ÊúâÂú®ËæìÂÖ•Âçï‰∏™ÊñáÊú¨ÊÆµËêΩÊó∂ÔºåÊ≠§ÂäüËÉΩÊâçÂèØÁî®„ÄÇ", icon="üëà")

    # 4. Text Clustering Analysis
    elif selected_analysis == "üß© ÊñáÊú¨ËÅöÁ±ªÂàÜÊûê":
        if len(raw_texts) < 2:
            st.warning("ÊñáÊú¨ËÅöÁ±ªËá≥Â∞ëÈúÄË¶Å‰∏§Êù°ÊñáÊú¨„ÄÇËØ∑Á≤òË¥¥Â§öË°åÊñáÊú¨Êàñ‰∏ä‰º†ÂåÖÂê´Â§öË°å/Â§ö‰∏™Êñá‰ª∂„ÄÇ", icon="‚ö†Ô∏è")
        else:
            st.subheader("‚öôÔ∏è ÊñáÊú¨ËÅöÁ±ªÂàÜÊûêÂèÇÊï∞ËÆæÁΩÆ")
            cluster_model_name = st.selectbox(
                "ÈÄâÊã©ËÅöÁ±ªÊ®°Âûã:",
                ("KMeans", "AgglomerativeClustering", "DBSCAN", "BIRCH"),
                key="cluster_model_select"
            )
            # Initialize clusters to None before the try block
            clusters = None 
            model_instance = None
            num_clusters_found = 0
            tfidf_matrix_dense = None # Ensure it's defined for later use, even if try block fails early
            linkage_agg = 'ward' # Default for Agglomerative, if needed before set
            metric_agg = 'euclidean' # Default for Agglomerative

            try:
                tfidf_vectorizer = TfidfVectorizer(
                    tokenizer=lambda x: list(jieba.cut(x)), max_df=0.90, min_df=2, stop_words=None
                )
                tfidf_matrix = tfidf_vectorizer.fit_transform(raw_texts)
                tfidf_matrix_dense = tfidf_matrix.toarray() 

                if tfidf_matrix.shape[0] < 2 or tfidf_matrix.shape[1] < 1:
                    st.error("ÁªèËøáTF-IDFÂ§ÑÁêÜÂêéÔºåÊñáÊú¨Êï∞ÊçÆ‰∏çË∂≥ÊàñÁâπÂæÅËøáÂ∞ë„ÄÇ")
                    st.stop()
                
                max_possible_clusters = min(tfidf_matrix.shape[0] - 1 if tfidf_matrix.shape[0] > 1 else 1, 20)
                if max_possible_clusters < 1 and cluster_model_name not in ["DBSCAN"]:
                     st.warning("ÊñáÊú¨Êï∞ÈáèËøáÂ∞ëÔºåÊó†Ê≥ïÊúâÊïàËÅöÁ±ª„ÄÇ")
                     st.stop()
                
                # --- Model Specific Parameters and Execution (copied from your last correct version) ---
                if cluster_model_name == "KMeans":
                    st.markdown("##### ‚ú® KMeans ÂèÇÊï∞")
                    num_clusters_kmeans = st.slider("KÂÄº:", min_value=2, max_value=max_possible_clusters if max_possible_clusters >=2 else 2, value=min(4, max_possible_clusters) if max_possible_clusters >=2 else 2, key="k_kmeans")
                    if tfidf_matrix.shape[0] < num_clusters_kmeans: st.error("ÊñáÊú¨Êï∞Â∞ë‰∫éKÂÄº!"); st.stop()
                    with st.spinner(f"KMeans (K={num_clusters_kmeans}) ËÅöÁ±ª‰∏≠..."):
                        model_instance = KMeans(n_clusters=num_clusters_kmeans, random_state=42, n_init='auto')
                        clusters = model_instance.fit_predict(tfidf_matrix)
                        num_clusters_found = num_clusters_kmeans
                elif cluster_model_name == "AgglomerativeClustering":
                    st.markdown("##### üîó Agglomerative Clustering ÂèÇÊï∞")
                    num_clusters_agg = st.slider("Á∞áÊï∞Èáè:", min_value=2, max_value=max_possible_clusters if max_possible_clusters >=2 else 2, value=min(4, max_possible_clusters) if max_possible_clusters >=2 else 2, key="k_agg")
                    linkage_agg = st.selectbox("LinkageÊñπÊ≥ï:", ('ward', 'complete', 'average', 'single'), key="linkage_agg")
                    metric_agg = 'euclidean' 
                    if tfidf_matrix.shape[0] < num_clusters_agg: st.error("ÊñáÊú¨Êï∞Â∞ë‰∫éÁ∞áÊï∞Èáè!"); st.stop()
                    with st.spinner(f"Agglomerative (k={num_clusters_agg}, linkage={linkage_agg}) ËÅöÁ±ª‰∏≠..."):
                        model_instance = AgglomerativeClustering(n_clusters=num_clusters_agg, metric=metric_agg, linkage=linkage_agg)
                        clusters = model_instance.fit_predict(tfidf_matrix_dense)
                        num_clusters_found = num_clusters_agg
                elif cluster_model_name == "DBSCAN":
                    st.markdown("##### üßê DBSCAN ÂèÇÊï∞")
                    eps_dbscan = st.number_input("Epsilon (eps - ÈÇªÂüüÂçäÂæÑ):", min_value=0.01, value=0.5, step=0.01, format="%.2f", key="eps_dbscan")
                    min_samples_dbscan = st.slider("Min Samples (Ê†∏ÂøÉÂØπË±°ÊúÄÂ∞èÊ†∑Êú¨Êï∞):", min_value=1, max_value=max(5, tfidf_matrix.shape[0] // 10), value=max(1,min(5, tfidf_matrix.shape[0] // 10 if tfidf_matrix.shape[0] // 10 >0 else 1)), key="min_samples_dbscan")
                    with st.spinner(f"DBSCAN (eps={eps_dbscan}, min_samples={min_samples_dbscan}) ËÅöÁ±ª‰∏≠..."):
                        model_instance = DBSCAN(eps=eps_dbscan, min_samples=min_samples_dbscan, metric='cosine')
                        clusters = model_instance.fit_predict(tfidf_matrix)
                        num_clusters_found = len(set(clusters)) - (1 if -1 in clusters else 0)
                        st.info(f"DBSCAN ÊâæÂà∞ {num_clusters_found} ‰∏™Á∞áÂíå {list(clusters).count(-1)} ‰∏™Á¶ªÁæ§ÁÇπ„ÄÇ")
                elif cluster_model_name == "BIRCH":
                    st.markdown("##### üå≥ BIRCH ÂèÇÊï∞")
                    threshold_birch = st.number_input("Threshold (CFÂ≠êÁ∞áÂçäÂæÑÈòàÂÄº):", min_value=0.01, value=0.5, step=0.05, format="%.2f", key="threshold_birch")
                    branching_factor_birch = st.slider("Branching Factor (CFÊ†ëÂàÜÊîØÂõ†Â≠ê):", min_value=2, max_value=100, value=50, key="branching_birch")
                    n_clusters_birch_options = [None] + list(range(2, (max_possible_clusters if max_possible_clusters >=2 else 2) + 1))
                    default_k_birch = min(3, max_possible_clusters) if max_possible_clusters >=2 else None
                    if default_k_birch == None and len(n_clusters_birch_options) > 1: default_k_birch = 2
                    num_clusters_birch_selected = st.select_slider("ÁõÆÊ†áÁ∞áÊï∞Èáè (K - NoneÂàôËá™Âä®Á°ÆÂÆö):", options=n_clusters_birch_options, value=default_k_birch, key="k_birch_slider")
                    with st.spinner(f"BIRCH (threshold={threshold_birch}, n_clusters={num_clusters_birch_selected}) ËÅöÁ±ª‰∏≠..."):
                        model_instance = Birch(threshold=threshold_birch, branching_factor=branching_factor_birch, n_clusters=num_clusters_birch_selected)
                        clusters = model_instance.fit_predict(tfidf_matrix)
                        if hasattr(model_instance, 'n_clusters_') and model_instance.n_clusters_ is not None: num_clusters_found = model_instance.n_clusters_
                        elif num_clusters_birch_selected is not None: num_clusters_found = num_clusters_birch_selected
                        else: num_clusters_found = len(set(clusters))
                        st.info(f"BIRCH ÊâæÂà∞/ËÆæÂÆö {num_clusters_found} ‰∏™Á∞á„ÄÇ")

            except ValueError as ve:
                st.error(f"ËÅöÁ±ªÂàÜÊûêÊó∂ÂèëÁîüÊï∞ÂÄºÈîôËØØ: {ve}")
                clusters = None # Ensure clusters is None if an error occurs
            except Exception as e:
                st.error(f"ËÅöÁ±ªÂàÜÊûêÊó∂ÂèëÁîüÊú™Áü•ÈîôËØØ: {e}")
                clusters = None # Ensure clusters is None if an error occurs

            # --- Displaying Results & Metrics & Visualizations (common for all models) ---
            # This block will only execute if clusters were successfully computed (clusters is not None)
            if clusters is not None:
                st.subheader("üìä ÊñáÊú¨ËÅöÁ±ªÂàÜÊûêÁªìÊûú")
                df_cluster_results = pd.DataFrame({'ÂéüÂßãÊñáÊú¨': raw_texts, 'ËÅöÁ±ªÊ†áÁ≠æ': clusters})
                st.markdown("#### üìã ÊñáÊú¨ËÅöÁ±ªÂàÜÈÖç:")
                st.dataframe(df_cluster_results, height=200, use_container_width=True)

                st.markdown("#### üìè ËÅöÁ±ªËØÑ‰º∞ÊåáÊ†á:")
                if num_clusters_found >= 2 and num_clusters_found < tfidf_matrix.shape[0]:
                    try:
                        sil_score = silhouette_score(tfidf_matrix, clusters, metric='cosine')
                        db_score = davies_bouldin_score(tfidf_matrix_dense, clusters)
                        st.metric(label="ËΩÆÂªìÁ≥ªÊï∞ (Silhouette Score)", value=f"{sil_score:.3f}", help="ËåÉÂõ¥[-1, 1]ÔºåË∂äÊé•Ëøë1Ë∂äÂ•Ω„ÄÇ‰ΩøÁî®‰ΩôÂº¶Ë∑ùÁ¶ªËÆ°ÁÆó„ÄÇ")
                        st.metric(label="Êà¥Áª¥ÊñØ-Â∏ÉÂ∞î‰∏ÅÊåáÊï∞ (Davies-Bouldin)", value=f"{db_score:.3f}", help="ÂÄºË∂äÂ∞èË∂äÂ•Ω„ÄÇ")
                    except ValueError as e_metric: st.warning(f"ËÆ°ÁÆóËØÑ‰º∞ÊåáÊ†áÊó∂Âá∫Èîô: {e_metric}„ÄÇ");
                    except Exception as e_metric_other: st.error(f"ËÆ°ÁÆóËØÑ‰º∞ÊåáÊ†áÊó∂ÂèëÁîüÊú™Áü•ÈîôËØØ: {e_metric_other}")
                else:
                    st.info(f"ÊâæÂà∞ {num_clusters_found} ‰∏™Á∞á„ÄÇËØÑ‰º∞ÊåáÊ†áÂú®Á∞áÊï∞Èáè‰∏∫ 2 Âà∞ (Ê†∑Êú¨Êï∞-1) ‰πãÈó¥Êó∂Êõ¥ÊúâÊÑè‰πâ„ÄÇ")
                
                st.markdown("### üñºÔ∏è ÂèØËßÜÂåñÂ±ïÊùø") # Was "--- Visualizations ---"
                with st.expander("ÈôçÁª¥Êï£ÁÇπÂõæËÆæÁΩÆ‰∏éÂèØËßÜÂåñ", expanded=True):
                    st.markdown("#### üìà ÈôçÁª¥Êï£ÁÇπÂõæ") # Was "**ËÅöÁ±ªÁªìÊûúÂèØËßÜÂåñ (ÈôçÁª¥Êï£ÁÇπÂõæ):**"
                    
                    vis_col_main_1, vis_col_main_2 = st.columns([2,1]) # Main columns for scatter controls

                    with vis_col_main_1: # Left column for primary controls
                        reduction_method = st.selectbox("ÈôçÁª¥ÊñπÊ≥ï:", ["PCA", "t-SNE"], key="reduction_scatter")
                        available_colormaps = plt.colormaps()
                        filtered_colormaps = [cm for cm in available_colormaps if not cm.endswith('_r')]
                        selected_colormap = st.selectbox("ÈÄâÊã©Ë∞ÉËâ≤Êùø:", filtered_colormaps, index=filtered_colormaps.index('viridis') if 'viridis' in filtered_colormaps else 0, key="colormap_scatter")
                        scatter_marker_styles_enabled = st.checkbox("‰∏∫‰∏çÂêåÁ∞áÂêØÁî®‰∏çÂêåÊ†áËÆ∞Ê†∑Âºè", False, key="scatter_marker_styles_cb")
                        scatter_show_grid = st.checkbox("ÊòæÁ§∫ÁΩëÊ†º", True, key="scatter_show_grid_cb")
                        
                    with vis_col_main_2: # Right column for size, alpha and colors
                        scatter_marker_size = st.slider("Ê†áËÆ∞Â§ßÂ∞è:", min_value=10, max_value=200, value=50, step=10, key="scatter_marker_size_slider")
                        scatter_marker_alpha = st.slider("Ê†áËÆ∞ÈÄèÊòéÂ∫¶:", min_value=0.1, max_value=1.0, value=0.7, step=0.05, key="scatter_marker_alpha_slider")
                        
                        # Horizontal layout for background and grid color pickers
                        color_col1, color_col2 = st.columns(2)
                        with color_col1:
                            scatter_bg_color = st.color_picker("ËÉåÊôØÈ¢úËâ≤", "#1E293B", key="scatter_bg_color_picker")
                        with color_col2:
                            if scatter_show_grid:
                                scatter_grid_color = st.color_picker("ÁΩëÊ†ºÈ¢úËâ≤", "#4B5563", key="scatter_grid_color_picker")
                            else:
                                scatter_grid_color = "#4B5563" # Default even if not shown, to prevent error
                    
                    perplexity_value = min(30.0, float(max(1, tfidf_matrix_dense.shape[0] - 2)))
                    if perplexity_value < 5: perplexity_value = 5
                    n_components_for_reduction = 2
                    
                    pca_explained_variance_ratio = None # Initialize

                    if tfidf_matrix_dense.shape[1] < n_components_for_reduction:
                        st.warning(f"TF-IDFÁâπÂæÅÊï∞ ({tfidf_matrix_dense.shape[1]}) Â∞ë‰∫éÈôçÁª¥ÁõÆÊ†á ({n_components_for_reduction})ÔºåÊó†Ê≥ïËøõË°åÊúâÊïàÈôçÁª¥ÂèØËßÜÂåñ„ÄÇ")
                        reduced_features = tfidf_matrix_dense[:, :tfidf_matrix_dense.shape[1]] 
                        if tfidf_matrix_dense.shape[1] == 1: 
                             reduced_features = np.hstack((reduced_features, np.zeros_like(reduced_features)))
                        elif tfidf_matrix_dense.shape[1] == 0:
                             reduced_features = np.zeros((tfidf_matrix_dense.shape[0], 2)) 
                    else:
                        if reduction_method == "PCA":
                            reducer = PCA(n_components=n_components_for_reduction, random_state=42)
                            reduced_features = reducer.fit_transform(tfidf_matrix_dense)
                            pca_explained_variance_ratio = reducer.explained_variance_ratio_
                        else: # t-SNE
                            reducer = TSNE(n_components=n_components_for_reduction, random_state=42, perplexity=perplexity_value, n_iter=300, init='pca', learning_rate='auto')
                            reduced_features = reducer.fit_transform(tfidf_matrix_dense)
                    
                    fig_scatter, ax_scatter = plt.subplots(figsize=(8, 6)) 
                    fig_scatter.patch.set_alpha(0) # Ensure figure background is transparent
                    # ax_scatter.patch.set_alpha(0) # ax facecolor is handled by plot_scatter_clusters bg_color

                    plot_scatter_clusters(ax_scatter, reduced_features, clusters, cluster_model_name,
                                          colormap=selected_colormap, 
                                          marker_size=scatter_marker_size, 
                                          marker_alpha=scatter_marker_alpha,
                                          marker_styles_enabled=scatter_marker_styles_enabled,
                                          bg_color=scatter_bg_color, 
                                          show_grid=scatter_show_grid, 
                                          grid_color=scatter_grid_color)
                    ax_scatter.set_title(f"{reduction_method} ÂèØËßÜÂåñ ({cluster_model_name})", fontsize=14)
                    st.pyplot(fig_scatter)

                    if pca_explained_variance_ratio is not None:
                        st.markdown("#### üí° PCA Ëß£ÈáäÊñπÂ∑ÆË¥°ÁåÆÔºö")
                        pca_col1, pca_col2, pca_col3 = st.columns(3)
                        pca_col1.metric("‰∏ªÊàêÂàÜ 1", f"{pca_explained_variance_ratio[0]:.2%}")
                        if len(pca_explained_variance_ratio) > 1:
                            pca_col2.metric("‰∏ªÊàêÂàÜ 2", f"{pca_explained_variance_ratio[1]:.2%}")
                            pca_col3.metric("Á¥ØËÆ°Ë¥°ÁåÆ", f"{np.sum(pca_explained_variance_ratio):.2%}")
                        else:
                            pca_col2.metric("Á¥ØËÆ°Ë¥°ÁåÆ", f"{np.sum(pca_explained_variance_ratio):.2%}")

                if cluster_model_name == "AgglomerativeClustering":
                    with st.expander("Â±ÇÊ¨°ËÅöÁ±ªÊ†ëÁä∂ÂõæËÆæÁΩÆ‰∏éÂèØËßÜÂåñ"):
                        st.markdown("#### üå≥ Â±ÇÊ¨°ËÅöÁ±ªÊ†ëÁä∂Âõæ") # Was "**Â±ÇÊ¨°ËÅöÁ±ªÊ†ëÁä∂Âõæ:**"
                        current_linkage_method = locals().get('linkage_agg', 'ward') 
                        current_metric = locals().get('metric_agg', 'euclidean')
                        
                        # Simplified dendrogram controls
                        dendro_orientation = st.selectbox("Ê†ëÁä∂ÂõæÊñπÂêë:", ['top', 'bottom', 'left', 'right'], index=0, key="dendro_orientation_simple_select")
                        default_color_thresh_simple = 0.7 * linkage(tfidf_matrix_dense, method=current_linkage_method, metric=current_metric)[:,2].max() if tfidf_matrix_dense is not None and tfidf_matrix_dense.size > 0 and tfidf_matrix_dense.shape[0] >1 else 0.0
                        dendro_color_threshold_simple = st.number_input("È¢úËâ≤ÈòàÂÄº (Ë∑ùÁ¶ª, 0Á¶ÅÁî®):", min_value=0.0, value=default_color_thresh_simple, step=0.1, key="dendro_color_thr_simple_input")
                        if dendro_color_threshold_simple <= 0: dendro_color_threshold_simple = None
                        
                        with st.spinner("ÁîüÊàêÊ†ëÁä∂Âõæ‰∏≠..."):
                            fig_dendro, ax_dendro = plt.subplots(figsize=(10, 7)) # Reverted to fixed height
                            plot_dynamic_dendrogram(ax_dendro, tfidf_matrix_dense, 
                                                    linkage_method=current_linkage_method, 
                                                    metric=current_metric,
                                                    orientation=dendro_orientation, 
                                                    color_threshold=dendro_color_threshold_simple)
                            st.pyplot(fig_dendro)
                            
            else: # This 'else' pairs with 'if clusters is not None:'
                # This will be shown if the clustering process in the try-except block failed and clusters remained None,
                # or if it's the initial state before any clustering is attempted for the current raw_texts.
                if selected_analysis == "üß© ÊñáÊú¨ËÅöÁ±ªÂàÜÊûê": # Only show this if we are in the clustering section
                    st.info("ËØ∑ÈÖçÁΩÆÂèÇÊï∞Âπ∂ËøêË°åËÅöÁ±ªÊ®°ÂûãÔºåÁªìÊûúÂíåÂèØËßÜÂåñÂ∞ÜÂú®Ê≠§ÊòæÁ§∫„ÄÇ")

else: # No raw_texts AND not on homepage
    if selected_analysis and selected_analysis != "üè† ‰∏ªÈ°µ": # Only show if an analysis was selected but no text
         st.info("ËØ∑Âú®‰∏äÊñπÁ≤òË¥¥ÊñáÊú¨„ÄÅ‰∏ä‰º†Êñá‰ª∂ÊàñËΩΩÂÖ•Á§∫‰æãÊï∞ÊçÆ‰ª•ÂºÄÂßãÂàÜÊûê„ÄÇ", icon="‚¨ÜÔ∏è")

st.sidebar.markdown("--- "*10)
st.sidebar.info("¬© 2024 ‰∏≠ÊñáNLPÊô∫ËÉΩÂàÜÊûêÂπ≥Âè∞") 